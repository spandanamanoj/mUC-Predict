{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034a61b7-ede5-4a56-970a-eab4e0bc8c08",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f37b9-6be8-4c48-851b-4e813e8b319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox,ttk\n",
    "from tqdm import tqdm\n",
    "import joblib  # For loading saved models (assuming your model is saved as a .pkl or similar file)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70eed9b-1113-417d-b8a2-dbcf42cca0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01f3bb-387a-41fe-aee2-4b47f988b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00334953-6233-42f3-9176-7b8a98bcf8d3",
   "metadata": {},
   "source": [
    "Save Prediction Results into The Downloads of a Local System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba251437-a16c-4aaa-a77b-933ac49e9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox\n",
    "from pathlib import Path\n",
    "\n",
    "def save_predictions_directly(predictions_df):\n",
    "    \n",
    "    # Replace 1 with 'Respondent' and 0 with 'Non-Respondent'\n",
    "    predictions_df['Prediction'] = predictions_df['Prediction'].replace({1: 'Respondent', 0: 'Non-Respondent'})\n",
    "    \n",
    "    # Get the default Downloads folder\n",
    "    downloads_path = str(Path.home() / \"Downloads\")\n",
    "    output_file = os.path.join(downloads_path, \"predictions.csv\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    messagebox.showinfo(\"Success\", f\"Prediction completed! File saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e7cb8-7912-4443-a418-8a5967d37431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store the prediction data\n",
    "predict_data = None\n",
    "normalization_confirmed = False  # Global flag to track whether the data is confirmed as normalized\n",
    "\n",
    "# Initialize the scaler globally\n",
    "scl = StandardScaler()\n",
    "\n",
    "# List of specified gene IDs\n",
    "specified_gene_ids = ['701', '890', '1869', '2187', '2491', '2556', '3619', '4085', '4283', '5111', '5426', '5557', '5984', '6502', \n",
    "                      '6529', '7298', '9133', '9700', '10036', '10090', '10403', '10615', '10959', '10992', '11339', '22983', \n",
    "                      '23397', '23649', '24137', '27101', '51514', '55143', '55355', '55388', '55723', '57149', '78995', '79733', \n",
    "                      '83540', '83903', '84318', '91687', '93323', '113130', '195828', '284367', '285643', '541468', '643677']\n",
    "# Reference mean and standard deviation for feature '701' in the training set\n",
    "reference_mean = 6.16178\n",
    "reference_std = 0.9687"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b1388-241c-48e9-88bf-c763f6a0e42e",
   "metadata": {},
   "source": [
    "Log2(TPM+1) transformation function for Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d5503-610c-4d7a-84ae-ddacdcb085ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log2(TPM+1) transformation function\n",
    "def log2p1(x):\n",
    "    return np.log2(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cb258-4ebf-40d5-aa9b-6f094b000f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize RNA-seq data using gene lengths\n",
    "def normalize_rna_seq_data(data, Org_data):\n",
    "    global normalize\n",
    "    try:      \n",
    "        \n",
    "        # Step 3: Transpose the RNA-seq feature selected data\n",
    "        gene_list_2021_train = np.transpose(data)\n",
    "        gene_list_2021_train.index.name = 'Entrez'\n",
    "        gene_list = gene_list_2021_train.index.tolist()\n",
    "\n",
    "        # Step 3: Transpose the RNA-seq full data\n",
    "        gene_list_2021_train1 = np.transpose(Org_data)\n",
    "        gene_list_2021_train1.index.name = 'Entrez'\n",
    "        gene_list1 = gene_list_2021_train1.index.tolist()\n",
    "      \n",
    "        gene_length_file_path = r'C:\\GUI\\Python\\fData.csv' # Change the path of this file\n",
    "        \n",
    "        # Load the gene length data\n",
    "        data_gene_length = pd.read_csv(gene_length_file_path)\n",
    "        print(f\"Gene length data loaded successfully, shape: {data_gene_length.shape}\")\n",
    "\n",
    "        # Step 3: Standardize Entrez IDs in gene length data\n",
    "        data_cleaned = data_gene_length.dropna(subset=['Entrez'])\n",
    "        data_cleaned['Entrez'] = data_cleaned['Entrez'].astype(int)\n",
    "     \n",
    "        # Convert gene_list to int64 for comparison\n",
    "        gene_list = [np.int32(gene) for gene in gene_list]\n",
    "        data_gene_length = data_cleaned[data_cleaned['Entrez'].isin(gene_list)]\n",
    "\n",
    "        gene_list1 = [np.int32(gene) for gene in gene_list1]\n",
    "        data_gene_length1 = data_cleaned[data_cleaned['Entrez'].isin(gene_list1)]\n",
    "\n",
    "        duplicated_rows = data_gene_length[data_gene_length.duplicated(subset='Entrez')]\n",
    "        data_gene_length = data_gene_length.drop_duplicates(subset='Entrez', keep='first')\n",
    "\n",
    "        duplicated_rows1 = data_gene_length1[data_gene_length1.duplicated(subset='Entrez')]\n",
    "        data_gene_length1 = data_gene_length1.drop_duplicates(subset='Entrez', keep='first')\n",
    "        \n",
    "        \n",
    "        # Convert 'Entrez' to a categorical type with a specific ordering\n",
    "        data_gene_length['Entrez'] = pd.Categorical(data_gene_length['Entrez'], categories = gene_list, ordered=True)\n",
    "        # Sort data_gene_length by the 'Entrez' column based on the specified order\n",
    "        data_gene_length = data_gene_length.sort_values('Entrez')\n",
    "        #print(\"data_gene_length is: \", data_gene_length.shape)\n",
    "\n",
    "\n",
    "        # Convert 'Entrez' to a categorical type with a specific ordering\n",
    "        data_gene_length1['Entrez'] = pd.Categorical(data_gene_length1['Entrez'], categories = gene_list1, ordered=True)\n",
    "        # Sort data_gene_length by the 'Entrez' column based on the specified order\n",
    "        data_gene_length1 = data_gene_length1.sort_values('Entrez')\n",
    "        #print(\"data_gene_length1 is: \", data_gene_length1.shape)\n",
    "\n",
    "        ################################################################################################################\n",
    "\n",
    "        # Step 5: Create a progress bar\n",
    "        progress_window = tk.Toplevel(root)\n",
    "        progress_window.title(\"Normalization Progress\")\n",
    "        progress_label = tk.Label(progress_window, text=\"Normalization in Progress...\", font=(\"Times New Roman\", 14))\n",
    "        progress_label.grid(pady=10)\n",
    "        progress_bar = ttk.Progressbar(progress_window, length=400, mode='determinate')\n",
    "        progress_bar.grid(pady=20)\n",
    "        \n",
    "        total_steps = len(data_gene_length) + len(data_gene_length1)\n",
    "        progress_bar['maximum'] = total_steps\n",
    "\n",
    "        #*************************************************************************************************************\n",
    "        \n",
    "        data_gene_TPM1 = gene_list_2021_train1.copy()\n",
    "        data_gene_TPM = gene_list_2021_train.copy()\n",
    "                        \n",
    "        # Step 4: Normalize the subset using the calculated denominator\n",
    "        for i in tqdm(range(len(data_gene_TPM1))):\n",
    "            data_gene_TPM1.iloc[i] = data_gene_TPM1.iloc[i] / data_gene_length1.iloc[i]['length']\n",
    "            progress_bar['value'] += 1\n",
    "            progress_window.update()\n",
    "            \n",
    "        for i in tqdm(range(len(data_gene_TPM))):\n",
    "            data_gene_TPM.iloc[i] = data_gene_TPM.iloc[i] / data_gene_length.iloc[i]['length']\n",
    "            progress_bar['value'] += 1\n",
    "            progress_window.update()\n",
    "    \n",
    "        # Step 5: Apply normalization to subset      \n",
    "        data_gene_TPM = data_gene_TPM / data_gene_TPM1.sum() * 1e6\n",
    "            \n",
    "        # Optional: Apply log2(x+1) transformation if needed\n",
    "        log2TPMp1 = np.vectorize(log2p1)(data_gene_TPM)\n",
    "        GUI_data_gene_log2TPMp1 = data_gene_TPM.copy()\n",
    "        GUI_data_gene_log2TPMp1.iloc[:, :] = log2TPMp1\n",
    "    \n",
    "        print(\"Normalization on subset completed successfully.\")\n",
    "        output_file = r\"C:\\GUI\\Python\\Normalized.csv\"  # Change the the path to save into your local system\n",
    "\n",
    "        #**************************************************************************************************************\n",
    "\n",
    "        # Make sure the Entrez column is included in the data\n",
    "        if 'Entrez' not in GUI_data_gene_log2TPMp1.columns:\n",
    "            if len(gene_list) == len(GUI_data_gene_log2TPMp1):\n",
    "                GUI_data_gene_log2TPMp1 = np.transpose(GUI_data_gene_log2TPMp1)\n",
    "                \n",
    "        else:\n",
    "            raise ValueError(\"Length of Entrez IDs does not match the data length.\")       \n",
    "            \n",
    "        # Save data including the Entrez column to the CSV file\n",
    "        if output_file:\n",
    "            GUI_data_gene_log2TPMp1.to_csv(output_file, index=False)  # Ensure index is not saved if you don't need it\n",
    "            print(f\"Data with Entrez saved successfully to {output_file}\")\n",
    "            messagebox.showinfo(\"Success\", \"Log(TPM+1) completed and saved successfully!\")\n",
    "        progress_window.destroy()\n",
    "\n",
    "        GUI_data_gene_log2TPMp2 = np.transpose(GUI_data_gene_log2TPMp1)\n",
    "        normalize = GUI_data_gene_log2TPMp1\n",
    "        \n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3c237-34f1-4a50-a0d0-14aeb08d8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    start_time = time.time()\n",
    "    global predict_data, specified_gene_ids, normalize\n",
    "    try:\n",
    "        \n",
    "        # Step 1: Load the RNA-seq data file\n",
    "        rna_seq_file_path = filedialog.askopenfilename(title=\"Select RNA-Seq Data File\", \n",
    "                                                       filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "        if not rna_seq_file_path:\n",
    "            messagebox.showerror(\"Error\", \"No RNA-seq file selected.\")\n",
    "            return  # Exit if no file is selected\n",
    "\n",
    "        # Step 2: Load the RNA-seq data\n",
    "        gene_data = pd.read_csv(rna_seq_file_path, index_col=0)\n",
    "    \n",
    "    \n",
    "        cleaned_column_names = [str(col).strip() for col in gene_data.columns]\n",
    "\n",
    "        # Update the DataFrame with cleaned column names\n",
    "        gene_data.columns = cleaned_column_names\n",
    "       #print(\"gene_data is: \", gene_data.head(5))\n",
    "\n",
    "        # Check for matching gene IDs\n",
    "        selected_columns = gene_data.columns.intersection(specified_gene_ids)\n",
    "        \n",
    "\n",
    "        # Debugging output to check if intersection worked correctly\n",
    "        print(\"Matched Columns:\", selected_columns.tolist())  # Debugging line\n",
    "\n",
    "        if selected_columns.empty:\n",
    "            messagebox.showwarning(\"Warning\", \"No matching gene IDs found in the data.\")\n",
    "            return  # Exit the function if no matching genes found\n",
    "\n",
    "        # Select the data based on the matching gene IDs\n",
    "        selected_data = gene_data[selected_columns]\n",
    "        \n",
    "        # Prompt the user to save the selected data\n",
    "        output_file = r\"C:\\GUI\\Python\\Feature_Selection.csv\"    # Change the the path to save into your local system\n",
    "        selected_data.to_csv(output_file, index=False)\n",
    "        messagebox.showinfo(\"Success\", \"Feature selection completed and saved successfully!\")\n",
    "        \n",
    "        if '701' in selected_data.columns:\n",
    "            feature_mean = selected_data['701'].mean()\n",
    "            \n",
    "                      \n",
    "            # Check if mean is within range of reference mean Â± reference std\n",
    "            if abs(feature_mean - reference_mean) > reference_std:\n",
    "                \n",
    "                # If not normalized, apply StandardScaler normalization\n",
    "                normalize_rna_seq_data(selected_data, gene_data)\n",
    "                #messagebox.showinfo(\"Info\", \"Data was not normalized. Normalization has been applied.\")\n",
    "            else:\n",
    "                messagebox.showinfo(\"Info\", \"Data is already normalized.\")\n",
    "                normalize = selected_data\n",
    "        \n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Feature '701' not found in the data.\")\n",
    "\n",
    "        # Store selected and normalized data for later prediction\n",
    "        predict_data = normalize\n",
    "        load_weights_and_predict()\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during feature selection: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e7832-fa60-436c-9ec5-e0dba5305dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the saved scaling parameters to new prediction data\n",
    "def scale_to_existing_scale(x, scale_info):\n",
    "    # Apply scaling using precomputed scale info\n",
    "    return (x - scale_info['center']) / scale_info['scale']\n",
    "\n",
    "def load_weights_and_predict():\n",
    "    global predict_data, specified_gene_ids\n",
    "    start_time = time.time()\n",
    "    # Check if predict_data is None or empty\n",
    "    if predict_data is None or predict_data.empty:\n",
    "        messagebox.showerror(\"Error\", \"No prediction data available. Please load the data first.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load the pre-trained model\n",
    "        model_weights_file = r'C:\\GUI\\Python\\best_logit_model.pkl'     # Change the path where the model weights are saved\n",
    "        model = joblib.load(model_weights_file)\n",
    "\n",
    "        # Load scaling parameters from the saved file\n",
    "        scale_info = joblib.load(r'C:\\GUI\\Python\\mUC_scaling_info.pkl')     # Change the path where the scaling file is saved\n",
    "        \n",
    "\n",
    "        # Check if the loaded object is a valid model by verifying if it has the 'predict' method\n",
    "        if not hasattr(model, 'predict'):\n",
    "            messagebox.showerror(\"Error\", \"Loaded model is not valid. It doesn't have a 'predict' method.\")\n",
    "            return\n",
    "\n",
    "        # Extract only the numeric columns for scaling\n",
    "        predict_data_numeric = predict_data.select_dtypes(include=[np.number])\n",
    "            \n",
    "        # Standardize the prediction data using the loaded scale_info\n",
    "        X_Pred_scaled = scale_to_existing_scale(predict_data_numeric.values, scale_info)\n",
    "        X_Pred_scaled_df = pd.DataFrame(X_Pred_scaled, columns=predict_data.columns)\n",
    "        X_Pred_scaled_df.to_csv(r'C:\\GUI\\Python\\GUIScaledtestset.csv', index=False)\n",
    "        \n",
    "        # Make predictions using the trained model\n",
    "        predictions = model.predict(X_Pred_scaled)\n",
    "       \n",
    "        # data_train = pd.read_csv(r'C:\\Spandana\\GUI\\Python_Train\\Final_File\\TPM\\LR_Model_Training\\Training_set\\log2TPM_training_FS_beforeStanberdization.csv')\n",
    "        df = pd.read_csv(r'C:\\GUI\\Python\\log2TPMp1_test.csv')    #Change the path of this file\n",
    "        df.columns.values[0] = 'SampleID'\n",
    "        sample_ids = df['SampleID'].tolist()\n",
    "       \n",
    "        # Ensure both arrays are of the same length\n",
    "        if len(sample_ids) != len(predictions):\n",
    "            raise ValueError(\"Mismatch between the number of Sample IDs and Predictions\")\n",
    "\n",
    "        # Print the lengths of the arrays to debug\n",
    "        print(f\"Number of Sample IDs: {len(sample_ids)}\")\n",
    "        print(f\"Number of Predictions: {len(predictions)}\")\n",
    "\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\n",
    "            \"SampleID\": sample_ids,\n",
    "            \"Prediction\": predictions\n",
    "        })\n",
    "       \n",
    "        # Replace 1 with 'Respondent' and 0 with 'Non-Respondent'\n",
    "        predictions_df['Prediction'] = predictions_df['Prediction'].replace({1: 'Respondent', 0: 'Non-Respondent'})\n",
    "\n",
    "\n",
    "        messagebox.showinfo(\"Success\", \"Prediction completed and saved successfully!\")\n",
    "       \n",
    "        save_predictions_directly(predictions_df)\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        messagebox.showinfo(\"Time Taken\", f\"Total processing time: {total_time:.2f} seconds\")\n",
    "        print(f\"Total time from start of processing to prediction completion: {total_time:.2f} seconds\")\n",
    "       \n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred during prediction: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46fee7b6-f854-4b8a-82f8-b95b5f2bf1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Drug Response Prediction\")\n",
    "root.geometry(\"750x500\")\n",
    "root.configure(bg=\"light blue\")\n",
    "\n",
    " # Configure a grid layout with a single centered column\n",
    "root.grid_columnconfigure(1, weight=1)  # This centers elements in column 0\n",
    "\n",
    "\n",
    "# Main Label\n",
    "title_label = tk.Label(root, text=\"Drug Response Prediction Tool\", font=(\"Times New Roman\", 18, 'bold'))\n",
    "title_label.grid(row=0, column=1, columnspan=5, pady=30)  # Center title\n",
    "\n",
    "\n",
    "# Test Data button with color\n",
    "test_data_button = tk.Button(\n",
    "    root, \n",
    "    text=\"Upload File\", \n",
    "    font=(\"Times New Roman\", 14, 'bold'), \n",
    "    command=preprocess_data,\n",
    "    bg=\"#a084ca\",  # Background color\n",
    "    fg=\"black\"       # Text color\n",
    ")\n",
    "test_data_button.grid(row=55, column=1, pady=50, padx=50, ipadx=50) \n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e7f311-219e-4357-9893-9617f915062c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81629f49-2481-4061-af4f-9d0d491a2c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead90e4-8401-491c-965b-437fbaf15e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6ce69-4a6f-4d0c-9111-12b3d4202d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mks",
   "language": "python",
   "name": "mks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
